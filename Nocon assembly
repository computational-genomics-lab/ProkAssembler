# Snakefile
# Microbial genome assembly pipeline for "Pure reads with minor contamination"
import os

# Configurations
configfile: "config.yaml"

# Define the rule to index input files
rule all:
    input:
        "results/checkm_post_polish/checkm_output/completeness.tsv",
        directory("results/busco_post_polish/"),
        "results/busco_post_polish/busco_summary.txt"
# Step 1: Flye Assembly
rule flye_assembly:
    input:
        reads=config["filtered_long_reads"]
    output:
        contigs="results/flye/assembly.fasta"
    params:
        threads=config["threads"],
    shell:
        """
        flye --nano-raw {input.reads} --out-dir results/flye --threads {params.threads}
        """

# Step 2: MetaBAT Binning
rule metabat_binning:
    input:
        contigs="results/flye/assembly.fasta"
    output:
        bins_dir=directory("results/metabat/bins")
    params:
        threads=config["threads"]
    shell:
        """
        mkdir -p {output.bins_dir}
        metabat2 -i {input.contigs} -o {output.bins_dir}/bin -t {params.threads}
        """

# Step 3: CheckM Quality Assessment
rule checkm_assessment:
    input:
        bins_dir="results/metabat/bins"
    output:
        checkm_dir=directory("results/checkm_post_flye/checkm_output"),
        completeness="results/checkm_post_flye/checkm_output/completeness.tsv"
    params:
        threads=config["threads"],
        lineage_wf_dir="results/checkm_post_flye/checkm_lineage_wf"
    shell:
        """
        mkdir -p {output.checkm_dir}
        checkm lineage_wf -x fa --tab_table -t {params.threads} {input.bins_dir} {params.lineage_wf_dir}
        checkm qa {params.lineage_wf_dir}/lineage.ms {params.lineage_wf_dir} > {output.completeness}
        """
# Step 4: Parse completeness.tsv to identify bins of the desired organism. Mention the the name of the organism in parse_completeness.py script
rule parse_completeness:
    input:
        completeness="results/checkm_post_flye/checkm_output/completeness.tsv"
    output:
        desired_bins="results/checkm_post_flye/desired_bins.txt"
    shell:
        "python parse_completeness.py {input.completeness} {output.desired_bins}"
# Step 5: Medaka Polishing
rule medaka_polish:
    input:
        reads=config["filtered_long_reads"],
        bins="results/checkm_post_flye/desired_bins.txt"
    output:
        touch("results/medaka/medaka_done")
    params:
        threads=config["threads"]
    run:
        # Read the list of bins
        with open(input.bins) as f:
            bins = [line.strip() for line in f]

        for bin_path in bins:
            # Define output directory for Medaka
            output_dir = bin_path.replace("results/metabat/bins", "results/medaka")
            output_dir = output_dir.replace(".fa", "")
            os.makedirs(output_dir, exist_ok=True)

            # Run Medaka consensus with filtered long reads and the assembly bin
            shell("""
                medaka_consensus -i {input.reads} -d {bin_path} -o {output_dir} -t {params.threads} 
            """)
# Step 6: PolyPolish Error Correction
# Snakefile
rule polypolish:
    input:
        consensus="results/medaka/medaka_done",  # Assuming the medaka outputs are the consensus files
        filtered_reads_r1=config["filtered_short_reads"]["R1"],
        filtered_reads_r2=config["filtered_short_reads"]["R2"],
        bins="results/checkm_post_flye/desired_bins.txt"
    output:
        touch("results/polypolish/polypolish_done")
    params:
        threads=config["threads"]
    run:
        # Read the list of bins
        with open(input.bins) as f:
            bins = [line.strip() for line in f]

        for bin_path in bins:
            # Define output directory for PolyPolish
            output_dir = bin_path.replace("results/metabat/bins", "results/polypolish")
            output_dir = output_dir.replace(".fa", "")
            os.makedirs(output_dir, exist_ok=True)

            # Define intermediate and output file paths
            consensus_fasta = bin_path
            index_prefix = os.path.join(output_dir, "consensus")
            sam1 = os.path.join(output_dir, "alignment_1.sam")
            sam2 = os.path.join(output_dir, "alignment_2.sam")
            filter_sam1 = os.path.join(output_dir, "filter_1.sam")
            filter_sam2 = os.path.join(output_dir, "filter_2.sam")
            polished_fasta = os.path.join(output_dir, "polypolish.fasta")

            # Run PolyPolish steps
            shell(f"""
                # Index the consensus assembly
                bwa index {consensus_fasta}

                # Align Illumina reads to the consensus
                bwa mem -t {params.threads} {consensus_fasta} {input.filtered_reads_r1} > {sam1}
                bwa mem -t {params.threads} {consensus_fasta} {input.filtered_reads_r2} > {sam2}

                # Filter alignments
                /home/sutripa/tools/Polypolish/scripts/polypolish_insert_filter.py --in1 {sam1} --in2 {sam2} --out1 {filter_sam1} --out2 {filter_sam2}

                # Run PolyPolish
                /home/sutripa/tools/Polypolish/target/release/polypolish {consensus_fasta} {filter_sam1} {filter_sam2} > {polished_fasta}
            """)
# Step 7: CheckM Quality Assessment on PolyPolish Corrected Bins
rule checkm_post_polish:
    input:
        polypolish_done="results/polypolish/polypolish_done",
        bins="results/checkm_post_flye/desired_bins.txt"
    output:
        checkm_dir=directory("results/checkm_post_polish/checkm_output"),
        completeness="results/checkm_post_polish/checkm_output/completeness.tsv"
    params:
        threads=config["threads"],
        lineage_wf_dir="results/checkm_post_polish/checkm_lineage_wf"
    run:
        import glob

        # Ensure the output directory exists
        os.makedirs(output.checkm_dir, exist_ok=True)

        # Initialize a list to collect completeness outputs
        completeness_outputs = []

        # Get a list of all polypolish bins (e.g., bin.1, bin.2, ...)
        bin_dirs = glob.glob("results/polypolish/bin.*")

        for bin_dir in bin_dirs:
            # Define the path to the polished fasta
            polished_bin_path = os.path.join(bin_dir)

            if not os.path.exists(polished_bin_path):
                continue  # Skip if the file doesn't exist

            # Define the output directory for CheckM
            bin_output_dir = os.path.join(output.checkm_dir, os.path.basename(bin_dir))
            os.makedirs(bin_output_dir, exist_ok=True)

            # Define the CheckM completeness output file
            completeness_output = os.path.join(bin_output_dir, "completeness.tsv")
            completeness_outputs.append(completeness_output)

            # Run CheckM
            shell(f"""
                checkm lineage_wf -x fasta --tab_table -t {params.threads} {polished_bin_path} {params.lineage_wf_dir}
                checkm qa {params.lineage_wf_dir}/lineage.ms {params.lineage_wf_dir} > {completeness_output}
            """)

        # Combine all completeness outputs into one file (if needed)
        with open(output.completeness, 'w') as out_file:
            for comp_output in completeness_outputs:
                with open(comp_output) as in_file:
                    out_file.write(in_file.read())
# Step 8: Busco Quality Assessment on PolyPolish Corrected Bins
rule busco_assessment:
    input:
        polypolish_done="results/polypolish/polypolish_done",
        bins="results/checkm_post_flye/desired_bins.txt"
    output:
        busco_dirs=directory("results/busco_post_polish/"),
        busco_summary="results/busco_post_polish/busco_summary.txt"
    params:
        threads=config["threads"],
        lineage=config["busco_lineage"]  # BUSCO lineage/dataset from config file
    run:
        import glob
        import datetime

        # Ensure the output directory exists
        os.makedirs(output.busco_dirs, exist_ok=True)

        # Initialize a list to collect BUSCO outputs
        busco_outputs = []

        # Get a list of all polypolish bins (e.g., bin.1, bin.2, ...)
        bin_dirs = glob.glob("results/polypolish/bin.*")

        for bin_dir in bin_dirs:
            # Define the path to the polished fasta
            polished_bin_path = os.path.join(bin_dir, "polypolish.fasta")

            if not os.path.exists(polished_bin_path):
                print(f"File not found: {polished_bin_path}")
                continue  # Skip if the file doesn't exist

            # Define the output directory for BUSCO, appending timestamp to ensure uniqueness
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            busco_output_dir = os.path.join(output.busco_dirs, os.path.basename(bin_dir) + "_" + timestamp)
            os.makedirs(busco_output_dir, exist_ok=True)

            # Run BUSCO with the -f flag to force overwrite if necessary
            shell(f"""
                busco -i {polished_bin_path} -o {busco_output_dir} -l {params.lineage} -m genome -c {params.threads} -f
            """)

            busco_outputs.append(busco_output_dir)

        # Optionally, summarize BUSCO results
        with open(output.busco_summary, 'w') as summary_file:
            for busco_dir in busco_outputs:
                summary_file.write(f"Results for {busco_dir}:\n")
                summary_files = glob.glob(os.path.join(busco_dir, "short_summary.*.txt"))
                if summary_files:
                    summary_file.write(open(summary_files[0]).read())
                else:
                    summary_file.write("No summary file found.\n")
                summary_file.write("\n")
