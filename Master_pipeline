
import os
import pandas as pd

# Configurations
configfile: "config.yaml"

# Define the rule to index input files
rule all:
    input:
        "contamination_category/checkm_post_flye/checkm_output/completeness.tsv",
        "contamination_category/final_pipeline_completed.flag"  # Flag to indicate completion of downstream pipeline

# Step 1: Flye Assembly
rule flye_assembly:
    input:
        reads=config["filtered_long_reads"]
    output:
        assembly_dir=directory("contamination_category/flye"),
    params:
        threads=config["threads"]
    shell:
        """
        flye --nano-raw {input.reads} --out-dir {output.assembly_dir} --threads {params.threads}
        """

# Step 2: CheckM contamination and heterogeneity assessment
rule checkm_assessment:
    input:
        assembly_dir="contamination_category/flye"
    output:
        checkm_dir=directory("contamination_category/checkm_post_flye/checkm_output"),
        completeness="contamination_category/checkm_post_flye/checkm_output/completeness.tsv"
    params:
        threads=config["threads"],
        lineage_wf_dir="contamination_category/checkm_post_flye/checkm_lineage_wf"
    shell:
        """
        mkdir -p {output.checkm_dir}
        checkm lineage_wf -x fasta --tab_table -t {params.threads} {input.assembly_dir} {params.lineage_wf_dir}
        checkm qa {params.lineage_wf_dir}/lineage.ms {params.lineage_wf_dir} --tab_table > {output.completeness}
        """

# Step 3: Select and run downstream pipeline
rule run_downstream_pipeline:
    input:
        completeness="contamination_category/checkm_post_flye/checkm_output/completeness.tsv"
    output:
        flag="contamination_category/final_pipeline_completed.flag"
    run:
        import pandas as pd

        # Open the file and manually find the start of data
        with open(input.completeness, 'r') as f:
            lines = f.readlines()
        
        # Find the line that starts the table ("Bin Id") and parse the subsequent rows
        for i, line in enumerate(lines):
            if line.startswith("Bin Id"):
                data_start = i + 1  # Data starts immediately after this line
                break
        
        # Load the table data into a DataFrame
        data = pd.read_csv(
            input.completeness,
            delim_whitespace=True,  # Use whitespace delimiter
            skiprows=data_start, 
            header=None,
            engine="python"
        )

        # Debugging step to inspect parsed data
        print(data)

        # Extract relevant columns for Contamination and Strain heterogeneity
        try:
            contamination = float(data.iloc[0, 13])  # Contamination (column 11 in table -> index 10)
            heterogeneity = float(data.iloc[0, 14])  # Strain heterogeneity (column 12 in table -> index 11)
        except IndexError:
            raise ValueError("Error parsing contamination or heterogeneity values from completeness.tsv.")

        # Determine the pipeline based on contamination and heterogeneity
        if contamination <= 1:
            selected_pipeline = "Nocon_assembly"
        elif 1 < contamination <= 7:
            selected_pipeline = "Lowcon_assembly"
        elif contamination > 7:
            if heterogeneity > 2:
                selected_pipeline = "HighconHetero_assembly"
            else:
                selected_pipeline = "Highcon_assembly"

   # Print the selected pipeline
        print(f"Selected pipeline: {selected_pipeline}")        
   # Run the selected pipeline
        import os
        os.system(f"snakemake --snakefile {selected_pipeline} --cores {config['threads']}")

        # Write a flag file to indicate completion
        with open(output.flag, "w") as f:
            f.write("Downstream pipeline completed.")


